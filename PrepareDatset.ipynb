{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4889efb5",
   "metadata": {},
   "source": [
    "Preparaci√≥n y extracci√≥n de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ef7ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: WinPcap is now deprecated (not maintained). Please use Npcap instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Procesando Dataset/onu\\ONU_capture_game_1.pcapng ‚Üí etiqueta: game\n",
      "üìÇ Procesando Dataset/onu\\ONU_capture_instant-message_1.pcapng ‚Üí etiqueta: instant-message\n",
      "üìÇ Procesando Dataset/onu\\ONU_capture_mail-service_1.pcapng ‚Üí etiqueta: mail\n",
      "üìÇ Procesando Dataset/onu\\ONU_capture_network-storage_1.pcapng ‚Üí etiqueta: network-storage\n",
      "üìÇ Procesando Dataset/onu\\ONU_capture_network-transmission_1.pcapng ‚Üí etiqueta: network-transmission\n",
      "üìÇ Procesando Dataset/onu\\ONU_capture_video_1.pcapng ‚Üí etiqueta: video\n",
      "üìÇ Procesando Dataset/onu\\ONU_capture_web-browsing_1.pcapng ‚Üí etiqueta: web-browsing\n",
      "                                      flow_id  packets  bytes    duration  \\\n",
      "0  210.196.16.152:2103-152.185.184.31:2103-17       45   6480  220.210560   \n",
      "1       61.139.26.122:60678-61.139.2.69:53-17       33   2988  296.189484   \n",
      "2       61.139.2.69:53-61.139.26.122:60678-17       33   5934  296.190030   \n",
      "3     61.139.26.122:44006-47.94.114.72:1443-6       29   3799   16.317012   \n",
      "4     47.94.114.72:1443-61.139.26.122:44006-6       32  33838   16.245598   \n",
      "\n",
      "   avg_pkt_size                     throughput class  \n",
      "0    144.000000  29.42638173210222071094138265  game  \n",
      "1     90.545455  10.08813668752669152831908104  game  \n",
      "2    179.818182  20.03443532518633392217827183  game  \n",
      "3    131.000000  232.8244901701365421561251533  game  \n",
      "4   1057.437500  2082.902703858608344241929414  game  \n",
      "‚úÖ Dataset completo guardado en dataset_all.csv\n"
     ]
    }
   ],
   "source": [
    "from scapy.all import rdpcap\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# === CONFIG ===\n",
    "pcap_dir = \"Dataset/onu/*_1.pcapng\"   # ruta a los pcaps\n",
    "dataset_out = \"Dataset/dataset_all.csv\"     #nombre de salida pcaps\n",
    "\n",
    "# Funci√≥n para mapear nombre de archivo a etiqueta\n",
    "def get_label_from_filename(filename):\n",
    "    name = os.path.basename(filename).lower()\n",
    "    if \"game\" in name:\n",
    "        return \"game\"\n",
    "    elif \"video\" in name:\n",
    "        return \"video\"\n",
    "    elif \"mail\" in name:\n",
    "        return \"mail\"\n",
    "    elif \"instant-message\" in name:\n",
    "        return \"instant-message\"\n",
    "    elif \"network-storage\" in name:\n",
    "        return \"network-storage\"\n",
    "    elif \"network-transmission\" in name:\n",
    "        return \"network-transmission\"\n",
    "    elif \"web-browsing\" in name:\n",
    "        return \"web-browsing\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Lista para el dataset final\n",
    "all_data = []\n",
    "\n",
    "# Procesar todos los PCAPs en la carpeta\n",
    "for pcap_file in glob.glob(pcap_dir):\n",
    "    app_label = get_label_from_filename(pcap_file)\n",
    "    print(f\"Procesando {pcap_file} ‚Üí etiqueta: {app_label}\")\n",
    "\n",
    "    packets = rdpcap(pcap_file)\n",
    "    flows = defaultdict(lambda: {\"packets\": 0, \"bytes\": 0, \"times\": []})\n",
    "\n",
    "    for pkt in packets:\n",
    "        if \"IP\" in pkt:\n",
    "            src = pkt[\"IP\"].src\n",
    "            dst = pkt[\"IP\"].dst\n",
    "            proto = pkt[\"IP\"].proto\n",
    "            sport = pkt.sport if hasattr(pkt, \"sport\") else 0\n",
    "            dport = pkt.dport if hasattr(pkt, \"dport\") else 0\n",
    "\n",
    "            flow_id = f\"{src}:{sport}-{dst}:{dport}-{proto}\"\n",
    "\n",
    "            flows[flow_id][\"packets\"] += 1\n",
    "            flows[flow_id][\"bytes\"] += len(pkt)\n",
    "            flows[flow_id][\"times\"].append(pkt.time)\n",
    "\n",
    "    # Construir dataset parcial para este PCAP\n",
    "    for fid, stats in flows.items():\n",
    "        times = stats[\"times\"]\n",
    "        duration = max(times) - min(times) if len(times) > 1 else 0\n",
    "        avg_pkt_size = stats[\"bytes\"] / stats[\"packets\"] if stats[\"packets\"] > 0 else 0\n",
    "        throughput = stats[\"bytes\"] / duration if duration > 0 else stats[\"bytes\"]\n",
    "\n",
    "        all_data.append({\n",
    "            \"flow_id\": fid,\n",
    "            \"packets\": stats[\"packets\"],\n",
    "            \"bytes\": stats[\"bytes\"],\n",
    "            \"duration\": duration,\n",
    "            \"avg_pkt_size\": avg_pkt_size,\n",
    "            \"throughput\": throughput,\n",
    "            \"class\": app_label\n",
    "        })\n",
    "\n",
    "# Convertir a DataFrame y guardar\n",
    "df = pd.DataFrame(all_data)\n",
    "print(df.head())\n",
    "df.to_csv(dataset_out, index=False)\n",
    "print(f\"Dataset completo guardado en {dataset_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed3cb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estad√≠sticas de features originales:\n",
      "            packets         bytes      duration  avg_pkt_size    throughput\n",
      "count  13022.000000  1.302200e+04  13022.000000  13022.000000  1.302200e+04\n",
      "mean     105.529181  6.334817e+04     19.342542    217.475339  4.993246e+05\n",
      "std      943.498048  7.776669e+05     51.582559    252.847231  1.532715e+07\n",
      "min        1.000000  5.400000e+01      0.000000     43.000000  5.328268e-01\n",
      "25%        1.000000  1.032500e+02      0.000000     74.000000  6.668191e+01\n",
      "50%        5.000000  4.190000e+02      0.163692    117.000000  1.300000e+02\n",
      "75%       11.000000  2.520500e+03     14.940699    257.700000  2.672351e+03\n",
      "max    39237.000000  3.843130e+07    301.382720   1504.949151  5.050000e+08\n",
      "‚úÖ Dataset balanceado y escalado guardado en 'dataset_balanced_scaled.csv'\n",
      "Distribuci√≥n de clases en el train set:\n",
      "class_encoded\n",
      "1    350\n",
      "0    350\n",
      "5    349\n",
      "6    349\n",
      "4    349\n",
      "3    349\n",
      "2    349\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargar dataset\n",
    "df = pd.read_csv(\"Dataset/dataset_all.csv\")\n",
    "\n",
    "# Estad√≠sticas b√°sicas antes del balanceo\n",
    "print(\"Estad√≠sticas de features originales:\")\n",
    "print(df[['packets','bytes','duration','avg_pkt_size','throughput']].describe())\n",
    "\n",
    "# Codificar etiquetas\n",
    "le = LabelEncoder()\n",
    "df['class_encoded'] = le.fit_transform(df['class'])\n",
    "\n",
    "# ===== Undersampling =====\n",
    "min_size = df['class_encoded'].value_counts().min()\n",
    "\n",
    "df_list = []\n",
    "for cls in df['class_encoded'].unique():\n",
    "    df_cls = df[df['class_encoded']==cls].sample(n=min_size, random_state=42)\n",
    "    df_list.append(df_cls)\n",
    "\n",
    "df_balanced = pd.concat(df_list).sample(frac=1, random_state=42)  # mezclar filas\n",
    "\n",
    "# Separar X / y\n",
    "features = ['packets','bytes','duration','avg_pkt_size','throughput']\n",
    "X = df_balanced[features]\n",
    "y = df_balanced['class_encoded']\n",
    "\n",
    "# Escalar features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Guardar dataset preprocesado y balanceado\n",
    "df_preprocessed = pd.DataFrame(X_scaled, columns=features)\n",
    "df_preprocessed['class_encoded'] = y.values\n",
    "df_preprocessed['class'] = le.inverse_transform(y.values)  # opcional, para referencia\n",
    "df_preprocessed.to_csv(\"Dataset/dataset_balanced_scaled.csv\", index=False)\n",
    "print(\"‚úÖ Dataset balanceado y escalado guardado en 'dataset_balanced_scaled.csv'\")\n",
    "\n",
    "# Separar train/test (opcional)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Distribuci√≥n de clases en el train set:\")\n",
    "print(pd.Series(y_train).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c982824d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras 5 filas del dataset:\n",
      "    packets     bytes  duration  avg_pkt_size  throughput  class_encoded  \\\n",
      "0 -0.084077 -0.073483 -0.375125     -0.601286   -0.031483              3   \n",
      "1 -0.085132 -0.073616 -0.379994     -0.601286   -0.031512              6   \n",
      "2 -0.085132 -0.073582 -0.379994     -0.535597   -0.031511              5   \n",
      "3 -0.084077 -0.073483 -0.379508     -0.601286   -0.031185              3   \n",
      "4 -0.085132 -0.073582 -0.379994     -0.535597   -0.031511              5   \n",
      "\n",
      "             class  \n",
      "0  network-storage  \n",
      "1     web-browsing  \n",
      "2            video  \n",
      "3  network-storage  \n",
      "4            video  \n",
      "\n",
      "Informaci√≥n general del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3493 entries, 0 to 3492\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   packets        3493 non-null   float64\n",
      " 1   bytes          3493 non-null   float64\n",
      " 2   duration       3493 non-null   float64\n",
      " 3   avg_pkt_size   3493 non-null   float64\n",
      " 4   throughput     3493 non-null   float64\n",
      " 5   class_encoded  3493 non-null   int64  \n",
      " 6   class          3493 non-null   object \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 191.2+ KB\n",
      "None\n",
      "\n",
      "Estad√≠sticas descriptivas:\n",
      "            packets         bytes      duration  avg_pkt_size    throughput  \\\n",
      "count  3.493000e+03  3.493000e+03  3.493000e+03  3.493000e+03  3.493000e+03   \n",
      "mean   1.830771e-17  4.475219e-17  7.729924e-17 -5.085476e-19  4.271800e-17   \n",
      "std    1.000143e+00  1.000143e+00  1.000143e+00  1.000143e+00  1.000143e+00   \n",
      "min   -8.513196e-02 -7.363308e-02 -3.799939e-01 -6.669743e-01 -3.151601e-02   \n",
      "25%   -8.513196e-02 -7.353871e-02 -3.799939e-01 -5.848636e-01 -3.151186e-02   \n",
      "50%   -8.091397e-02 -7.294888e-02 -3.761790e-01 -4.185896e-01 -3.150761e-02   \n",
      "75%   -7.458699e-02 -6.879437e-02 -9.119472e-02  9.791782e-02 -3.136011e-02   \n",
      "max    4.128910e+01  3.176253e+01  5.402561e+00  5.317798e+00  3.409603e+01   \n",
      "\n",
      "       class_encoded  \n",
      "count    3493.000000  \n",
      "mean        3.000000  \n",
      "std         2.000286  \n",
      "min         0.000000  \n",
      "25%         1.000000  \n",
      "50%         3.000000  \n",
      "75%         5.000000  \n",
      "max         6.000000  \n",
      "\n",
      "N√∫mero de flujos por clase:\n",
      "class\n",
      "network-storage         499\n",
      "web-browsing            499\n",
      "video                   499\n",
      "instant-message         499\n",
      "mail                    499\n",
      "game                    499\n",
      "network-transmission    499\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_file = \"Dataset/dataset_balanced_scaled.csv\"\n",
    "df = pd.read_csv(dataset_file)\n",
    "\n",
    "# === Mostrar las primeras filas ===\n",
    "print(\"Primeras 5 filas del dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# === Mostrar informaci√≥n general ===\n",
    "print(\"\\nInformaci√≥n general del dataset:\")\n",
    "print(df.info())\n",
    "\n",
    "# === Estad√≠sticas b√°sicas de las columnas num√©ricas ===\n",
    "print(\"\\nEstad√≠sticas descriptivas:\")\n",
    "print(df.describe())\n",
    "\n",
    "# === Mostrar conteo de clases ===\n",
    "print(\"\\nN√∫mero de flujos por clase:\")\n",
    "print(df['class'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
